{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af73278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total json files: 100\n",
      "dict_keys(['messages', 'response', 'args', 'kwargs', 'timestamp', 'cost'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "json_path = '/home/v-murongma/code/OpenHands/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/Qwen3-Coder-30B-A3B-Instruct_maxiter_100_N_v0.59.0-no-hint-run_1/llm_completions/astropy__astropy-7166/openai__Qwen__Qwen3-Coder-30B-A3B-Instruct-1761820634.000126.json'\n",
    "json_path = '/home/v-murongma/code/OpenHands/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/Qwen3-Coder-30B-A3B-Instruct_maxiter_100_N_v0.59.0-no-hint-run_1/llm_completions/astropy__astropy-7166/openai__Qwen__Qwen3-Coder-30B-A3B-Instruct-1761820634.000126.json'\n",
    "\n",
    "json_dir = '/home/v-murongma/code/OpenHands/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/Qwen3-Coder-30B-A3B-Instruct_maxiter_100_N_v0.59.0-no-hint-run_1_1/llm_completions/astropy__astropy-7166/'\n",
    "json_dir = '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/gpt-4.1_maxiter_100_N_v0.61.0-no-hint/gpt-4.1_maxiter_100_N_v0.61.0-no-hint-run_4/llm_completions/django__django-12663'\n",
    "json_path_list = sorted([os.path.join(json_dir, f) for f in os.listdir(json_dir) if f.endswith('.json')])\n",
    "print(f'Total json files: {len(json_path_list)}')\n",
    "\n",
    "# json_path = '/home/v-murongma/code/OpenHands/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/Qwen3-Coder-30B-A3B-Instruct_maxiter_100_N_v0.59.0-no-hint-run_1/llm_completions/astropy__astropy-7166/openai__Qwen__Qwen3-Coder-30B-A3B-Instruct-1761820714.370487.json'\n",
    "with open(json_path_list[0], 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e975cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for json_file in json_path_list:\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    print(len(data['response']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843f0ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'description', 'parameters'])\n"
     ]
    }
   ],
   "source": [
    "with open(json_path_list[0], 'r') as f:\n",
    "    data = json.load(f)\n",
    "# print(data.keys())\n",
    "# pretty-print the third message (use json.dumps since data[...] is a dict)\n",
    "\n",
    "print(data['kwargs']['tools'][0]['function'].keys())\n",
    "# print([tool['function']['name'] for tool in data['kwargs']['tools']])\n",
    "\n",
    "# print(json.dumps(data['kwargs'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eccf218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data['cost'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb78531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "JSON STRUCTURE INSPECTOR\n",
      "============================================================\n",
      "\n",
      "Usage examples:\n",
      "  inspect_json_structure(data)  # Default settings\n",
      "  inspect_json_structure(data, max_depth=5)  # Limit depth\n",
      "  inspect_json_structure(data, max_list_items=5)  # Show more list items\n",
      "  inspect_json_structure(data, max_str_len=200)  # Show longer strings\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def inspect_json_structure(obj, max_depth=10, current_depth=0, max_list_items=3, max_str_len=100):\n",
    "    \"\"\"\n",
    "    Recursively inspect JSON structure, showing types and structure without full content.\n",
    "    \n",
    "    Args:\n",
    "        obj: The object to inspect (dict, list, or primitive)\n",
    "        max_depth: Maximum recursion depth\n",
    "        current_depth: Current recursion level\n",
    "        max_list_items: How many list items to show as examples\n",
    "        max_str_len: Maximum string length to display\n",
    "    \n",
    "    Returns:\n",
    "        String representation of the structure\n",
    "    \"\"\"\n",
    "    indent = \"  \" * current_depth\n",
    "    \n",
    "    if current_depth >= max_depth:\n",
    "        return f\"{indent}[MAX DEPTH REACHED]\"\n",
    "    \n",
    "    if obj is None:\n",
    "        return \"null\"\n",
    "    \n",
    "    elif isinstance(obj, bool):\n",
    "        return str(obj)\n",
    "    \n",
    "    elif isinstance(obj, (int, float)):\n",
    "        return f\"{obj}\"\n",
    "    \n",
    "    elif isinstance(obj, str):\n",
    "        if len(obj) <= max_str_len:\n",
    "            return f'\"{obj}\"'\n",
    "        else:\n",
    "            preview = obj[:max_str_len]\n",
    "            return f'\"{preview}...\" (length: {len(obj)})'\n",
    "    \n",
    "    elif isinstance(obj, dict):\n",
    "        if not obj:\n",
    "            return \"{}\"\n",
    "        \n",
    "        lines = [\"{\"]\n",
    "        keys = list(obj.keys())\n",
    "        for i, key in enumerate(keys):\n",
    "            value = obj[key]\n",
    "            \n",
    "            # Determine value type for annotation\n",
    "            if isinstance(value, dict):\n",
    "                type_info = f\"dict({len(value)} keys)\"\n",
    "            elif isinstance(value, list):\n",
    "                type_info = f\"list({len(value)} items)\"\n",
    "            elif isinstance(value, str):\n",
    "                type_info = f\"string({len(value)})\"\n",
    "            elif value is None:\n",
    "                type_info = \"null\"\n",
    "            else:\n",
    "                type_info = type(value).__name__\n",
    "            \n",
    "            value_str = inspect_json_structure(\n",
    "                value, \n",
    "                max_depth=max_depth, \n",
    "                current_depth=current_depth + 1,\n",
    "                max_list_items=max_list_items,\n",
    "                max_str_len=max_str_len\n",
    "            )\n",
    "            \n",
    "            # Add proper indentation and formatting\n",
    "            is_last = (i == len(keys) - 1)\n",
    "            comma = \"\" if is_last else \",\"\n",
    "            \n",
    "            # Handle multiline values\n",
    "            if '\\n' in value_str:\n",
    "                lines.append(f'{indent}  \"{key}\": // {type_info}')\n",
    "                # Indent the multiline value properly\n",
    "                indented_value = '\\n'.join(indent + '  ' + line if line.strip() else line \n",
    "                                           for line in value_str.split('\\n'))\n",
    "                lines.append(indented_value.rstrip() + comma)\n",
    "            else:\n",
    "                lines.append(f'{indent}  \"{key}\": {value_str}{comma}')\n",
    "        \n",
    "        lines.append(f\"{indent}}}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    elif isinstance(obj, list):\n",
    "        if not obj:\n",
    "            return \"[]\"\n",
    "        \n",
    "        lines = [\"[\"]\n",
    "        \n",
    "        # Show first few items as examples\n",
    "        num_to_show = min(max_list_items, len(obj))\n",
    "        for i in range(num_to_show):\n",
    "            item_str = inspect_json_structure(\n",
    "                obj[i],\n",
    "                max_depth=max_depth,\n",
    "                current_depth=current_depth + 1,\n",
    "                max_list_items=max_list_items,\n",
    "                max_str_len=max_str_len\n",
    "            )\n",
    "            \n",
    "            is_last = (i == num_to_show - 1 and len(obj) <= num_to_show)\n",
    "            comma = \"\" if is_last else \",\"\n",
    "            \n",
    "            # Handle multiline items\n",
    "            if '\\n' in item_str:\n",
    "                # Indent the multiline item properly\n",
    "                indented_item = '\\n'.join(indent + '  ' + line if line.strip() else line \n",
    "                                         for line in item_str.split('\\n'))\n",
    "                lines.append(indented_item.rstrip() + comma)\n",
    "            else:\n",
    "                lines.append(f\"{indent}  {item_str}{comma}\")\n",
    "        \n",
    "        if len(obj) > num_to_show:\n",
    "            lines.append(f\"{indent}  ... ({len(obj) - num_to_show} more items)\")\n",
    "        \n",
    "        lines.append(f\"{indent}]\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    else:\n",
    "        return f\"<{type(obj).__name__}>: {str(obj)[:max_str_len]}\"\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(\"=\"*60)\n",
    "print(\"JSON STRUCTURE INSPECTOR\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nUsage examples:\")\n",
    "print(\"  inspect_json_structure(data)  # Default settings\")\n",
    "print(\"  inspect_json_structure(data, max_depth=5)  # Limit depth\")\n",
    "print(\"  inspect_json_structure(data, max_list_items=5)  # Show more list items\")\n",
    "print(\"  inspect_json_structure(data, max_str_len=200)  # Show longer strings\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25e9bd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['messages', 'response', 'args', 'kwargs', 'timestamp', 'cost'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ba7369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LAST RESPONSE CONTENT\n",
      "============================================================\n",
      "\n",
      "{\n",
      "  \"id\": \"chatcmpl-CiJVpsO5YNYvLAZIL1f7IXJt8fuor\",\n",
      "  \"created\": 1764677473,\n",
      "  \"model\": \"azure/o3-mini-2025-01-31\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_52e4403cb8\",\n",
      "  \"choices\": // list(1 items)\n",
      "  [\n",
      "      {\n",
      "            \"finish_reason\": \"tool_calls\",\n",
      "            \"index\": 0,\n",
      "            \"message\": // dict(5 keys)\n",
      "            {\n",
      "                    \"content\": null,\n",
      "                    \"role\": \"assistant\",\n",
      "                    \"tool_calls\": // list(1 items)\n",
      "                    [\n",
      "                              {\n",
      "                                          \"function\": // dict(2 keys)\n",
      "                                          {\n",
      "                                                        \"arguments\": \"{\"command\": \"grep -R \\\"def get_prep_value\\\" /workspace/django__django__3.1/django/db/models/fields/\", \"security_risk\": \"LOW\"}\",\n",
      "                                                        \"name\": \"execute_bash\"\n",
      "                                                      },\n",
      "                                          \"id\": \"call_htorInFCbeElm4iKYZFFORNx\",\n",
      "                                          \"type\": \"function\"\n",
      "                                        }\n",
      "                            ],\n",
      "                    \"function_call\": null,\n",
      "                    \"annotations\": []\n",
      "                  },\n",
      "            \"provider_specific_fields\": // dict(1 keys)\n",
      "            {\n",
      "                    \"content_filter_results\": {}\n",
      "                  }\n",
      "          }\n",
      "    ],\n",
      "  \"usage\": // dict(5 keys)\n",
      "  {\n",
      "      \"completion_tokens\": 552,\n",
      "      \"prompt_tokens\": 5936,\n",
      "      \"total_tokens\": 6488,\n",
      "      \"completion_tokens_details\": // dict(5 keys)\n",
      "      {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 448,\n",
      "            \"rejected_prediction_tokens\": 0,\n",
      "            \"text_tokens\": null\n",
      "          },\n",
      "      \"prompt_tokens_details\": // dict(4 keys)\n",
      "      {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 5760,\n",
      "            \"text_tokens\": null,\n",
      "            \"image_tokens\": null\n",
      "          }\n",
      "    },\n",
      "  \"service_tier\": null,\n",
      "  \"prompt_filter_results\": // list(1 items)\n",
      "  [\n",
      "      {\n",
      "            \"prompt_index\": 0,\n",
      "            \"content_filter_results\": // dict(5 keys)\n",
      "            {\n",
      "                    \"hate\": // dict(2 keys)\n",
      "                    {\n",
      "                              \"filtered\": False,\n",
      "                              \"severity\": \"safe\"\n",
      "                            },\n",
      "                    \"jailbreak\": // dict(2 keys)\n",
      "                    {\n",
      "                              \"filtered\": False,\n",
      "                              \"detected\": False\n",
      "                            },\n",
      "                    \"self_harm\": // dict(2 keys)\n",
      "                    {\n",
      "                              \"filtered\": False,\n",
      "                              \"severity\": \"safe\"\n",
      "                            },\n",
      "                    \"sexual\": // dict(2 keys)\n",
      "                    {\n",
      "                              \"filtered\": False,\n",
      "                              \"severity\": \"safe\"\n",
      "                            },\n",
      "                    \"violence\": // dict(2 keys)\n",
      "                    {\n",
      "                              \"filtered\": False,\n",
      "                              \"severity\": \"safe\"\n",
      "                            }\n",
      "                  }\n",
      "          }\n",
      "    ]\n",
      "}\n",
      "\n",
      "============================================================\n",
      "INSPECTING FULL LLM COMPLETION JSON STRUCTURE\n",
      "============================================================\n",
      "\n",
      "4\n",
      "[\n",
      "  {\n",
      "      \"content\": [],\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": // list(1 items)\n",
      "      [\n",
      "            {\n",
      "                    \"id\": \"call_wsEr7F8Tr3P3zzX6J0JGavyP\",\n",
      "                    \"type\": \"function\",\n",
      "                    \"function\": // dict(2 keys)\n",
      "                    {\n",
      "                              \"name\": \"execute_bash\",\n",
      "                              \"arguments\": \"{\"command\": \"grep -R \\\"class SimpleLazyObject\\\" /workspace/django__django__3.1/django/utils/functional.py\", \"security_risk\": \"LOW\"}\"\n",
      "                            }\n",
      "                  }\n",
      "          ]\n",
      "    },\n",
      "  {\n",
      "      \"content\": // list(1 items)\n",
      "      [\n",
      "            {\n",
      "                    \"type\": \"text\",\n",
      "                    \"text\": // string(235)\n",
      "                    \"class SimpleLazyObject(LazyObject):\n",
      "                    [The command completed with exit code 0.]\n",
      "                    [Current working directory: /workspace/django__django__3.1]\n",
      "                    [Python interpreter: /opt/miniconda3/envs/testbed/bin/python]\n",
      "                    [Command finished with exit code 0]\"\n",
      "                  }\n",
      "          ],\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_wsEr7F8Tr3P3zzX6J0JGavyP\",\n",
      "      \"name\": \"execute_bash\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "json_dir = '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/gpt-4.1_maxiter_100_N_v0.61.0-no-hint/gpt-4.1_maxiter_100_N_v0.61.0-no-hint-run_5/llm_completions/django__django-12663'\n",
    "json_dir = '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/o3-mini_maxiter_100_N_v0.61.0-no-hint/o3-mini_maxiter_100_N_v0.61.0-no-hint-run_2/llm_completions/django__django-12663'\n",
    "# json_dir = '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/o1-mini_maxiter_100_N_v0.61.0-no-hint-run_1/llm_completions/django__django-12663'\n",
    "json_path_list = sorted([os.path.join(json_dir, f) for f in os.listdir(json_dir) if f.endswith('.json')])\n",
    "# Test the inspector on your LLM completion data\n",
    "step = 1\n",
    "with open(json_path_list[step], 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LAST RESPONSE CONTENT\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "structure = inspect_json_structure(data['response'], max_depth=10, max_list_items=60, max_str_len=30000)\n",
    "print(structure)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSPECTING FULL LLM COMPLETION JSON STRUCTURE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(len(data['messages']))\n",
    "structure = inspect_json_structure(data['messages'][step*2:], max_depth=10, max_list_items=60, max_str_len=30000)\n",
    "print(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "246a03c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-e23bb86ee676498aaf54b42e38cccdbf\",\n",
      "  \"created\": 1762163851,\n",
      "  \"model\": \"Qwen/Qwen3-Coder-30B-A3B-Instruct\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"choices\": // list(1 items)\n",
      "  [\n",
      "      {\n",
      "            \"finish_reason\": \"tool_calls\",\n",
      "            \"index\": 0,\n",
      "            \"message\": // dict(4 keys)\n",
      "            {\n",
      "                    \"content\": null,\n",
      "                    \"role\": \"assistant\",\n",
      "                    \"tool_calls\": // list(1 items)\n",
      "                    [\n",
      "                              {\n",
      "                                          \"function\": // dict(2 keys)\n",
      "                                          {\n",
      "                                                        \"arguments\": \"{\"command\": \"cd /workspace/dask__dask__2022.7 && ls -la\", \"security_risk\": \"LOW\"}\",\n",
      "                                                        \"name\": \"execute_bash\"\n",
      "                                                      },\n",
      "                                          \"id\": \"chatcmpl-tool-edac3335786b43d48adb11f99203273a\",\n",
      "                                          \"type\": \"function\"\n",
      "                                        }\n",
      "                            ],\n",
      "                    \"function_call\": null\n",
      "                  },\n",
      "            \"provider_specific_fields\": // dict(2 keys)\n",
      "            {\n",
      "                    \"stop_reason\": null,\n",
      "                    \"token_ids\": null\n",
      "                  }\n",
      "          }\n",
      "    ],\n",
      "  \"usage\": // dict(5 keys)\n",
      "  {\n",
      "      \"completion_tokens\": 54,\n",
      "      \"prompt_tokens\": 9305,\n",
      "      \"total_tokens\": 9359,\n",
      "      \"completion_tokens_details\": null,\n",
      "      \"prompt_tokens_details\": null\n",
      "    },\n",
      "  \"service_tier\": null,\n",
      "  \"prompt_logprobs\": null,\n",
      "  \"prompt_token_ids\": null,\n",
      "  \"kv_transfer_params\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "structure = inspect_json_structure(data['response'], max_depth=10, max_list_items=60, max_str_len=30000)\n",
    "print(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33142bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INSPECTING FULL LLM COMPLETION JSON STRUCTURE\n",
      "============================================================\n",
      "\n",
      "8\n",
      "[\n",
      "  {\n",
      "      \"content\": [],\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": // list(1 items)\n",
      "      [\n",
      "            {\n",
      "                    \"id\": \"chatcmpl-tool-edac3335786b43d48adb11f99203273a\",\n",
      "                    \"type\": \"function\",\n",
      "                    \"function\": // dict(2 keys)\n",
      "                    {\n",
      "                              \"name\": \"execute_bash\",\n",
      "                              \"arguments\": \"{\"command\": \"cd /workspace/dask__dask__2022.7 && ls -la\", \"security_risk\": \"LOW\"}\"\n",
      "                            }\n",
      "                  }\n",
      "          ]\n",
      "    },\n",
      "  {\n",
      "      \"content\": // list(1 items)\n",
      "      [\n",
      "            {\n",
      "                    \"type\": \"text\",\n",
      "                    \"text\": // string(1447)\n",
      "                    \"total 152\n",
      "                    drwxr-xr-x 9 root root  4096 Nov  3 09:57 .\n",
      "                    drwxrwxr-x 3 root root  4096 Nov  3 09:57 ..\n",
      "                    -rw-r--r-- 1 root root   243 Nov  3 09:57 .coveragerc\n",
      "                    drwxr-xr-x 8 root root  4096 Nov  3 09:57 .git\n",
      "                    -rw-r--r-- 1 root root   669 Nov  3 09:57 .git-blame-ignore-revs\n",
      "                    drwxr-xr-x 3 root root  4096 Nov  3 09:57 .github\n",
      "                    -rw-r--r-- 1 root root   304 Nov  3 09:57 .gitignore\n",
      "                    -rw-r--r-- 1 root root  1517 Nov  3 09:57 .pre-commit-config.yaml\n",
      "                    -rw-r--r-- 1 root root   285 Nov  3 09:57 .readthedocs.yaml\n",
      "                    -rw-r--r-- 1 root root   239 Nov  3 09:57 CONTRIBUTING.md\n",
      "                    -rw-r--r-- 1 root root  1531 Nov  3 09:57 LICENSE.txt\n",
      "                    -rw-r--r-- 1 root root   325 Nov  3 09:57 MANIFEST.in\n",
      "                    -rw-r--r-- 1 root root  1291 Nov  3 09:57 README.rst\n",
      "                    drwxr-xr-x 2 root root  4096 Nov  3 09:57 __pycache__\n",
      "                    -rw-r--r-- 1 root root   685 Nov  3 09:57 codecov.yml\n",
      "                    -rw-r--r-- 1 root root  1726 Nov  3 09:57 conftest.py\n",
      "                    drwxr-xr-x 5 root root  4096 Nov  3 09:57 continuous_integration\n",
      "                    drwxr-xr-x 9 root root  4096 Nov  3 09:57 dask\n",
      "                    drwxr-xr-x 2 root root  4096 Nov  3 09:57 dask.egg-info\n",
      "                    drwxr-xr-x 3 root root  4096 Nov  3 09:57 docs\n",
      "                    -rw-r--r-- 1 root root  2758 Nov  3 09:57 setup.cfg\n",
      "                    -rwxr-xr-x 1 root root  2878 Nov  3 09:57 setup.py\n",
      "                    -rw-r--r-- 1 root root 65478 Nov  3 09:57 versioneer.py\n",
      "                    [The command completed with exit code 0.]\n",
      "                    [Current working directory: /workspace/dask__dask__2022.7]\n",
      "                    [Python interpreter: /opt/miniconda3/envs/testbed/bin/python]\n",
      "                    [Command finished with exit code 0]\"\n",
      "                  }\n",
      "          ],\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"chatcmpl-tool-edac3335786b43d48adb11f99203273a\",\n",
      "      \"name\": \"execute_bash\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Test the inspector on your LLM completion data\n",
    "step = 3\n",
    "with open(json_path_list[step], 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSPECTING FULL LLM COMPLETION JSON STRUCTURE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(len(data['messages']))\n",
    "structure = inspect_json_structure(data['messages'][step*2:], max_depth=10, max_list_items=60, max_str_len=30000)\n",
    "print(structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b5f03",
   "metadata": {},
   "source": [
    "# Extracting Tool Use Trajectories\n",
    "\n",
    "The `messages` array contains the conversation history between the agent and tools. The trajectory consists of:\n",
    "- **Assistant messages with tool_calls**: Agent decides to use a tool\n",
    "- **Tool messages**: Result/observation from tool execution\n",
    "\n",
    "Let's extract and visualize this trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7bd179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOOL USE TRAJECTORY EXTRACTOR\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def extract_tool_trajectory(messages):\n",
    "    \"\"\"\n",
    "    Extract tool use trajectory from messages array.\n",
    "    \n",
    "    Returns a list of trajectory steps, where each step contains:\n",
    "    - step_num: Sequential step number\n",
    "    - action: Tool call information (tool name, arguments)\n",
    "    - observation: Tool result/output\n",
    "    \"\"\"\n",
    "    trajectory = []\n",
    "    step_num = 0\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(messages):\n",
    "        msg = messages[i]\n",
    "        \n",
    "        # Look for assistant messages with tool_calls\n",
    "        if msg.get('role') == 'assistant' and 'tool_calls' in msg:\n",
    "            tool_calls = msg['tool_calls']\n",
    "            \n",
    "            # Get assistant's reasoning/text if present\n",
    "            assistant_text = \"\"\n",
    "            if 'content' in msg and msg['content']:\n",
    "                if isinstance(msg['content'], list):\n",
    "                    for content_item in msg['content']:\n",
    "                        if content_item.get('type') == 'text':\n",
    "                            assistant_text = content_item.get('text', '')\n",
    "                            break\n",
    "                elif isinstance(msg['content'], str):\n",
    "                    assistant_text = msg['content']\n",
    "            \n",
    "            # Process each tool call\n",
    "            for tool_call in tool_calls:\n",
    "                step_num += 1\n",
    "                tool_id = tool_call.get('id', '')\n",
    "                tool_type = tool_call.get('type', '')\n",
    "                function_info = tool_call.get('function', {})\n",
    "                tool_name = function_info.get('name', 'unknown')\n",
    "                tool_args = function_info.get('arguments', '')\n",
    "                \n",
    "                # Parse arguments if it's a JSON string\n",
    "                try:\n",
    "                    tool_args_dict = json.loads(tool_args) if isinstance(tool_args, str) else tool_args\n",
    "                except:\n",
    "                    tool_args_dict = tool_args\n",
    "                \n",
    "                # Find the corresponding tool response\n",
    "                observation = None\n",
    "                for j in range(i + 1, len(messages)):\n",
    "                    if messages[j].get('role') == 'tool' and messages[j].get('tool_call_id') == tool_id:\n",
    "                        obs_content = messages[j].get('content', '')\n",
    "                        if isinstance(obs_content, list):\n",
    "                            for content_item in obs_content:\n",
    "                                if content_item.get('type') == 'text':\n",
    "                                    observation = content_item.get('text', '')\n",
    "                                    break\n",
    "                        elif isinstance(obs_content, str):\n",
    "                            observation = obs_content\n",
    "                        break\n",
    "                \n",
    "                trajectory.append({\n",
    "                    'step_num': step_num,\n",
    "                    'assistant_thought': assistant_text,\n",
    "                    'tool_name': tool_name,\n",
    "                    'tool_args': tool_args_dict,\n",
    "                    'observation': observation or '[No observation found]'\n",
    "                })\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return trajectory\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(\"=\"*80)\n",
    "print(\"TOOL USE TRAJECTORY EXTRACTOR\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e575c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total json files: 26\n",
      "messages length: 52\n",
      "\n",
      "Total steps: 20\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STEP 1\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: execute_bash\n",
      "   Arguments:\n",
      "     - command: grep -R \"def get_prep_value\" -n ./django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   grep: ./django__django__3.1/django/db/models/fields/__init__.py: No such file or directory\n",
      "[The command completed with exit code 2.]\n",
      "[Current working directory: /workspace/django__django__3.1]\n",
      "[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]\n",
      "[Command finished with exit code 2]\n",
      "\n",
      "================================================================================\n",
      "STEP 2\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: execute_bash\n",
      "   Arguments:\n",
      "     - command: grep -R 'def get_prep_value' -n django__django__3.1\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   grep: django__django__3.1: No such file or directory\n",
      "[The command completed with exit code 2.]\n",
      "[Current working directory: /workspace/django__django__3.1]\n",
      "[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]\n",
      "[Command finished with exit code 2]\n",
      "\n",
      "================================================================================\n",
      "STEP 3\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: execute_bash\n",
      "   Arguments:\n",
      "     - command: find . -maxdepth=2 | sort\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   find: unknown predicate `-maxdepth=2'\n",
      "[The command completed with exit code 0.]\n",
      "[Current working directory: /workspace/django__django__3.1]\n",
      "[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]\n",
      "[Command finished with exit code 0]\n",
      "\n",
      "================================================================================\n",
      "STEP 4\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: execute_bash\n",
      "   Arguments:\n",
      "     - command: find . -type d -maxdepth 2 | sort\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   find: warning: you have specified the global option -maxdepth after the argument -type, but global options are not positional, i.e., -maxdepth affects tests specified before it as well as those specified after it.  Please specify global options before other arguments.\n",
      ".\n",
      "./.git\n",
      "./.git/branches\n",
      "./.git/hooks\n",
      "./.git/info\n",
      "./.git/logs\n",
      "./.git/objects\n",
      "./.git/refs\n",
      "./.github\n",
      "./.tx\n",
      "./Django.egg-info\n",
      "./django\n",
      "./django/__pycache__\n",
      "./django/apps\n",
      "./django/bin\n",
      "./django/conf\n",
      "./django/contrib\n",
      "./django/core\n",
      "./django/db\n",
      "./django/dispatch\n",
      "./django/forms\n",
      "./django/http\n",
      "./django/middleware\n",
      "./django/template\n",
      "./django/templatetags\n",
      "./django/test\n",
      "./django/urls\n",
      "./django/utils\n",
      "./django/views\n",
      "./docs\n",
      "./docs/_ext\n",
      "./docs/_theme\n",
      "./docs/faq\n",
      "./docs/howto\n",
      "./docs/internals\n",
      "./docs/intro\n",
      "./docs/man\n",
      "./docs/misc\n",
      "./docs/ref\n",
      "./docs/releases\n",
      "./docs/topics\n",
      "./extras\n",
      "./js_tests\n",
      "./js_tests/admin\n",
      "./js_tests/gis\n",
      "./scripts\n",
      "./tests\n",
      "./tests/absolute_url_overrides\n",
      "./tests/admin_autodiscover\n",
      "./tests/admin_changelist\n",
      "./tests/admin_checks\n",
      "./te...\n",
      "\n",
      "================================================================================\n",
      "STEP 5\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: execute_bash\n",
      "   Arguments:\n",
      "     - command: find django -type d -path 'django/db/models/fields'\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   django/db/models/fields\n",
      "[The command completed with exit code 0.]\n",
      "[Current working directory: /workspace/django__django__3.1]\n",
      "[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]\n",
      "[Command finished with exit code 0]\n",
      "\n",
      "================================================================================\n",
      "STEP 6\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: execute_bash\n",
      "   Arguments:\n",
      "     - command: find django/db/models/fields -type f\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   django/db/models/fields/proxy.py\n",
      "django/db/models/fields/mixins.py\n",
      "django/db/models/fields/files.py\n",
      "django/db/models/fields/__init__.py\n",
      "django/db/models/fields/reverse_related.py\n",
      "django/db/models/fields/related_lookups.py\n",
      "django/db/models/fields/related.py\n",
      "django/db/models/fields/related_descriptors.py\n",
      "[The command completed with exit code 0.]\n",
      "[Current working directory: /workspace/django__django__3.1]\n",
      "[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]\n",
      "[Command finished with exit code 0]\n",
      "\n",
      "================================================================================\n",
      "STEP 7\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: view\n",
      "     - path: django/db/models/fields/__init__.py\n",
      "     - security_risk: LOW\n",
      "     - view_range: [1, 150]\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   ERROR:\n",
      "Invalid `path` parameter: django/db/models/fields/__init__.py. The path should be an absolute path, starting with `/`.\n",
      "\n",
      "================================================================================\n",
      "STEP 8\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: view\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - security_risk: LOW\n",
      "     - view_range: [1, 150]\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   Here's the result of running `cat -n` on /workspace/django__django__3.1/django/db/models/fields/__init__.py:\n",
      "     1\timport collections.abc\n",
      "     2\timport copy\n",
      "     3\timport datetime\n",
      "     4\timport decimal\n",
      "     5\timport operator\n",
      "     6\timport uuid\n",
      "     7\timport warnings\n",
      "     8\tfrom base64 import b64decode, b64encode\n",
      "     9\tfrom functools import partialmethod, total_ordering\n",
      "    10\t\n",
      "    11\tfrom django import forms\n",
      "    12\tfrom django.apps import apps\n",
      "    13\tfrom django.conf import settings\n",
      "    14\tfrom django.core import checks, exceptions, validators\n",
      "    15\tfrom django.db import connection, connections, router\n",
      "    16\tfrom django.db.models.constants import LOOKUP_SEP\n",
      "    17\tfrom django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n",
      "    18\tfrom django.utils import timezone\n",
      "    19\tfrom django.utils.datastructures import DictWrapper\n",
      "    20\tfrom django.utils.dateparse import (\n",
      "    21\t    parse_date, parse_datetime, parse_duration, parse_time,\n",
      "    22\t)\n",
      "    23\tfrom django.util...\n",
      "\n",
      "================================================================================\n",
      "STEP 9\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: view\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - security_risk: LOW\n",
      "     - view_range: [800, 850]\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   Here's the result of running `cat -n` on /workspace/django__django__3.1/django/db/models/fields/__init__.py:\n",
      "   800\t        \"\"\"Return field's value just before saving.\"\"\"\n",
      "   801\t        return getattr(model_instance, self.attname)\n",
      "   802\t\n",
      "   803\t    def get_prep_value(self, value):\n",
      "   804\t        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "   805\t        if isinstance(value, Promise):\n",
      "   806\t            value = value._proxy____cast()\n",
      "   807\t        return value\n",
      "   808\t\n",
      "   809\t    def get_db_prep_value(self, value, connection, prepared=False):\n",
      "   810\t        \"\"\"\n",
      "   811\t        Return field's value prepared for interacting with the database backend.\n",
      "   812\t\n",
      "   813\t        Used by the default implementations of get_db_prep_save().\n",
      "   814\t        \"\"\"\n",
      "   815\t        if not prepared:\n",
      "   816\t            value = self.get_prep_value(value)\n",
      "   817\t        return value\n",
      "   818\t\n",
      "   819\t    def get_db_prep_save(self, value, connection):\n",
      "   820\t        \"\"\"Return field's va...\n",
      "\n",
      "================================================================================\n",
      "STEP 10\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: insert\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - insert_line: 805\n",
      "     - new_str: from django.utils.functional import SimpleLazyObject\n",
      "    if isinstance(value, SimpleLazyObject):\n",
      "        value = value._wrapped if hasattr(value, '_wrapped') else value...\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   The file /workspace/django__django__3.1/django/db/models/fields/__init__.py has been edited. Here's the result of running `cat -n` on a snippet of the edited file:\n",
      "   802\t\n",
      "   803\t    def get_prep_value(self, value):\n",
      "   804\t        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "   805\t        if isinstance(value, Promise):\n",
      "   806\tfrom django.utils.functional import SimpleLazyObject\n",
      "   807\t    if isinstance(value, SimpleLazyObject):\n",
      "   808\t        value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "   809\t            value = value._proxy____cast()\n",
      "   810\t        return value\n",
      "   811\t\n",
      "   812\t    def get_db_prep_value(self, value, connection, prepared=False):\n",
      "   813\t\n",
      "Review the changes and make sure they are as expected (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\n",
      "\n",
      "================================================================================\n",
      "STEP 11\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: str_replace\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - old_str: def get_prep_value(self, value):\n",
      "        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "        if isinstance(value, Promise):\n",
      "            value = value._proxy____cast()\n",
      "        return value...\n",
      "     - new_str: def get_prep_value(self, value):\n",
      "        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "        from django.utils.functional import SimpleLazyObject\n",
      "        if isinstance(value, SimpleLazyObject):\n",
      "            value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "        if isinstance(value, Promise):\n",
      "            value = value._proxy____cast()\n",
      "        return value...\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   ERROR:\n",
      "No replacement was performed, old_str `def get_prep_value(self, value):\n",
      "        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "        if isinstance(value, Promise):\n",
      "            value = value._proxy____cast()\n",
      "        return value` did not appear verbatim in /workspace/django__django__3.1/django/db/models/fields/__init__.py.\n",
      "\n",
      "================================================================================\n",
      "STEP 12\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: str_replace\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - old_str:         if isinstance(value, Promise):\n",
      "            value = value._proxy____cast()\n",
      "     - new_str:         from django.utils.functional import SimpleLazyObject\n",
      "        if isinstance(value, SimpleLazyObject):\n",
      "            value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "        if isinstance(value, Promise):\n",
      "            value = value._proxy____cast()...\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   ERROR:\n",
      "No replacement was performed, old_str `if isinstance(value, Promise):\n",
      "            value = value._proxy____cast()` did not appear verbatim in /workspace/django__django__3.1/django/db/models/fields/__init__.py.\n",
      "\n",
      "================================================================================\n",
      "STEP 13\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: view\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - security_risk: LOW\n",
      "     - view_range: [800, 820]\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   Here's the result of running `cat -n` on /workspace/django__django__3.1/django/db/models/fields/__init__.py:\n",
      "   800\t        \"\"\"Return field's value just before saving.\"\"\"\n",
      "   801\t        return getattr(model_instance, self.attname)\n",
      "   802\t\n",
      "   803\t    def get_prep_value(self, value):\n",
      "   804\t        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "   805\t        if isinstance(value, Promise):\n",
      "   806\tfrom django.utils.functional import SimpleLazyObject\n",
      "   807\t    if isinstance(value, SimpleLazyObject):\n",
      "   808\t        value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "   809\t            value = value._proxy____cast()\n",
      "   810\t        return value\n",
      "   811\t\n",
      "   812\t    def get_db_prep_value(self, value, connection, prepared=False):\n",
      "   813\t        \"\"\"\n",
      "   814\t        Return field's value prepared for interacting with the database backend.\n",
      "   815\t\n",
      "   816\t        Used by the default implementations of get_db_prep_save().\n",
      "   817\t        \"\"\"\n",
      "   818\t        if not pre...\n",
      "\n",
      "================================================================================\n",
      "STEP 14\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: str_replace\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - old_str:     def get_prep_value(self, value):\n",
      "        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "        if isinstance(value, Promise):\n",
      "        from django.utils.functional import SimpleLazyObject\n",
      "    if isinstance(value, SimpleLazyObject):\n",
      "        value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "            value = value._proxy____cast()\n",
      "        return value...\n",
      "     - new_str:     def get_prep_value(self, value):\n",
      "        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "        from django.utils.functional import SimpleLazyObject\n",
      "        if isinstance(value, SimpleLazyObject):\n",
      "            value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "        if isinstance(value, Promise):\n",
      "            value = value._proxy____cast()\n",
      "        return value...\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   ERROR:\n",
      "No replacement was performed, old_str `def get_prep_value(self, value):\n",
      "        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "        if isinstance(value, Promise):\n",
      "        from django.utils.functional import SimpleLazyObject\n",
      "    if isinstance(value, SimpleLazyObject):\n",
      "        value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "            value = value._proxy____cast()\n",
      "        return value` did not appear verbatim in /workspace/django__django__3.1/django/db/models/fields/__init__.py.\n",
      "\n",
      "================================================================================\n",
      "STEP 15\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: view\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - security_risk: LOW\n",
      "     - view_range: [803, 812]\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   Here's the result of running `cat -n` on /workspace/django__django__3.1/django/db/models/fields/__init__.py:\n",
      "   803\t    def get_prep_value(self, value):\n",
      "   804\t        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "   805\t        if isinstance(value, Promise):\n",
      "   806\tfrom django.utils.functional import SimpleLazyObject\n",
      "   807\t    if isinstance(value, SimpleLazyObject):\n",
      "   808\t        value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "   809\t            value = value._proxy____cast()\n",
      "   810\t        return value\n",
      "   811\t\n",
      "   812\t    def get_db_prep_value(self, value, connection, prepared=False):\n",
      "\n",
      "\n",
      "================================================================================\n",
      "STEP 16\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: view\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - security_risk: LOW\n",
      "     - view_range: [803, 812]\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   Here's the result of running `cat -n` on /workspace/django__django__3.1/django/db/models/fields/__init__.py:\n",
      "   803\t    def get_prep_value(self, value):\n",
      "   804\t        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "   805\t        if isinstance(value, Promise):\n",
      "   806\tfrom django.utils.functional import SimpleLazyObject\n",
      "   807\t    if isinstance(value, SimpleLazyObject):\n",
      "   808\t        value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "   809\t            value = value._proxy____cast()\n",
      "   810\t        return value\n",
      "   811\t\n",
      "   812\t    def get_db_prep_value(self, value, connection, prepared=False):\n",
      "\n",
      "\n",
      "================================================================================\n",
      "STEP 17\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: str_replace\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - old_str:         def get_prep_value(self, value):\n",
      "            \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "            if isinstance(value, Promise):\n",
      "    from django.utils.functional import SimpleLazyObject\n",
      "        if isinstance(value, SimpleLazyObject):\n",
      "            value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "                value = value._proxy____cast()\n",
      "            return value...\n",
      "     - new_str:         def get_prep_value(self, value):\n",
      "            \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "            from django.utils.functional import SimpleLazyObject\n",
      "            if isinstance(value, SimpleLazyObject):\n",
      "                value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "            if isinstance(value, Promise):\n",
      "                value = value._proxy____cast()\n",
      "            return value...\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   ERROR:\n",
      "No replacement was performed, old_str `def get_prep_value(self, value):\n",
      "            \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "            if isinstance(value, Promise):\n",
      "    from django.utils.functional import SimpleLazyObject\n",
      "        if isinstance(value, SimpleLazyObject):\n",
      "            value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "                value = value._proxy____cast()\n",
      "            return value` did not appear verbatim in /workspace/django__django__3.1/django/db/models/fields/__init__.py.\n",
      "\n",
      "================================================================================\n",
      "STEP 18\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: view\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - security_risk: LOW\n",
      "     - view_range: [800, 815]\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   Here's the result of running `cat -n` on /workspace/django__django__3.1/django/db/models/fields/__init__.py:\n",
      "   800\t        \"\"\"Return field's value just before saving.\"\"\"\n",
      "   801\t        return getattr(model_instance, self.attname)\n",
      "   802\t\n",
      "   803\t    def get_prep_value(self, value):\n",
      "   804\t        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "   805\t        if isinstance(value, Promise):\n",
      "   806\tfrom django.utils.functional import SimpleLazyObject\n",
      "   807\t    if isinstance(value, SimpleLazyObject):\n",
      "   808\t        value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "   809\t            value = value._proxy____cast()\n",
      "   810\t        return value\n",
      "   811\t\n",
      "   812\t    def get_db_prep_value(self, value, connection, prepared=False):\n",
      "   813\t        \"\"\"\n",
      "   814\t        Return field's value prepared for interacting with the database backend.\n",
      "   815\t\n",
      "\n",
      "\n",
      "================================================================================\n",
      "STEP 19\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: str_replace\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - old_str:         if isinstance(value, Promise):\n",
      "\tfrom django.utils.functional import SimpleLazyObject\n",
      "\t    if isinstance(value, SimpleLazyObject):\n",
      "\t        value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "\t                value = value._proxy____cast()\n",
      "\t        return value...\n",
      "     - new_str:         from django.utils.functional import SimpleLazyObject\n",
      "        if isinstance(value, SimpleLazyObject):\n",
      "            value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "        if isinstance(value, Promise):\n",
      "            value = value._proxy____cast()\n",
      "        return value...\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   ERROR:\n",
      "No replacement was performed, old_str `if isinstance(value, Promise):\n",
      "\tfrom django.utils.functional import SimpleLazyObject\n",
      "\t    if isinstance(value, SimpleLazyObject):\n",
      "\t        value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "\t                value = value._proxy____cast()\n",
      "\t        return value` did not appear verbatim in /workspace/django__django__3.1/django/db/models/fields/__init__.py.\n",
      "\n",
      "================================================================================\n",
      "STEP 20\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ TOOL CALL: str_replace_editor\n",
      "   Arguments:\n",
      "     - command: str_replace\n",
      "     - path: /workspace/django__django__3.1/django/db/models/fields/__init__.py\n",
      "     - old_str:         if isinstance(value, Promise):\n",
      "from django.utils.functional import SimpleLazyObject\n",
      "    if isinstance(value, SimpleLazyObject):\n",
      "        value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "            value = value._proxy____cast()\n",
      "        return value...\n",
      "     - new_str:         from django.utils.functional import SimpleLazyObject\n",
      "        if isinstance(value, SimpleLazyObject):\n",
      "            value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "        if isinstance(value, Promise):\n",
      "            value = value._proxy____cast()\n",
      "        return value...\n",
      "     - security_risk: LOW\n",
      "\n",
      "ðŸ“‹ OBSERVATION:\n",
      "   The file /workspace/django__django__3.1/django/db/models/fields/__init__.py has been edited. Here's the result of running `cat -n` on a snippet of /workspace/django__django__3.1/django/db/models/fields/__init__.py:\n",
      "   802\t\n",
      "   803\t    def get_prep_value(self, value):\n",
      "   804\t        \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n",
      "   805\t        from django.utils.functional import SimpleLazyObject\n",
      "   806\t        if isinstance(value, SimpleLazyObject):\n",
      "   807\t            value = value._wrapped if hasattr(value, '_wrapped') else value\n",
      "   808\t        if isinstance(value, Promise):\n",
      "   809\t            value = value._proxy____cast()\n",
      "   810\t        return value\n",
      "   811\t\n",
      "   812\t    def get_db_prep_value(self, value, connection, prepared=False):\n",
      "   813\t        \"\"\"\n",
      "   814\t        Return field's value prepared for interacting with the database backend.\n",
      "   815\t\n",
      "Review the changes and make sure they are as expected. Edit the file again if necessary.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# json_dir = '/home/v-murongma/code/OpenHands/evaluation/evaluation_outputs/outputs/SWE-Gym__SWE-Gym-train/CodeActAgent/Qwen3-Coder-30B-A3B-Instruct_maxiter_100_N_v0.59.0-no-hint-train-qwen3_coder_30b_a3b_instruct-t0-run_1___/llm_completions/dask__dask-9285'\n",
    "# json_dir = '/home/v-murongma/code/OpenHands/evaluation/evaluation_outputs/outputs/SWE-Gym__SWE-Gym-train/CodeActAgent/Qwen3-Coder-30B-A3B-Instruct_maxiter_100_N_v0.59.0-no-hint-train-qwen3_coder_30b_a3b_instruct-t0-run_1_parall10/llm_completions/dask__dask-9285'\n",
    "json_dir = '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/gpt-4.1_maxiter_100_N_v0.61.0-no-hint/gpt-4.1_maxiter_100_N_v0.61.0-no-hint-run_4/llm_completions/django__django-12663'\n",
    "json_dir = '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/gpt-4.1_maxiter_100_N_v0.61.0-no-hint/gpt-4.1_maxiter_100_N_v0.61.0-no-hint-run_1/llm_completions/django__django-12663'\n",
    "json_dir = '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/o3-mini_maxiter_100_N_v0.61.0-no-hint/o3-mini_maxiter_100_N_v0.61.0-no-hint-run_5/llm_completions/django__django-12663'\n",
    "# json_dir = '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/o4-mini_maxiter_100_N_v0.61.0-no-hint-run_1/llm_completions/django__django-12663'\n",
    "\n",
    "json_path_list = sorted([os.path.join(json_dir, f) for f in os.listdir(json_dir) if f.endswith('.json')])\n",
    "print(f'Total json files: {len(json_path_list)}')\n",
    "\n",
    "# json_path = '/home/v-murongma/code/OpenHands/evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/Qwen3-Coder-30B-A3B-Instruct_maxiter_100_N_v0.59.0-no-hint-run_1/llm_completions/astropy__astropy-7166/openai__Qwen__Qwen3-Coder-30B-A3B-Instruct-1761820714.370487.json'\n",
    "\n",
    "with open(json_path_list[-1], 'r') as f:\n",
    "    data = json.load(f)\n",
    "# Extract trajectory from the loaded messages\n",
    "print('messages length:', len(data['messages']))\n",
    "trajectory = extract_tool_trajectory(data['messages'])\n",
    "\n",
    "print(f\"\\nTotal steps: {len(trajectory)}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display each step\n",
    "for step in trajectory:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STEP {step['step_num']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Show assistant's thought (if any)\n",
    "    if step['assistant_thought']:\n",
    "        thought_preview = step['assistant_thought'][:200] + \"...\" if len(step['assistant_thought']) > 200 else step['assistant_thought']\n",
    "        print(f\"\\nðŸ’­ ASSISTANT THOUGHT:\")\n",
    "        print(f\"   {thought_preview}\")\n",
    "    \n",
    "    # Show tool call\n",
    "    print(f\"\\nðŸ”§ TOOL CALL: {step['tool_name']}\")\n",
    "    print(f\"   Arguments:\")\n",
    "    for key, value in step['tool_args'].items():\n",
    "        value_str = str(value)\n",
    "        if len(value_str) > 100:\n",
    "            value_str = value_str[:500] + \"...\"\n",
    "        print(f\"     - {key}: {value_str}\")\n",
    "    \n",
    "    # Show observation\n",
    "    print(f\"\\nðŸ“‹ OBSERVATION:\")\n",
    "    obs_preview = step['observation'][:1000] + \"...\" if len(step['observation']) > 1000 else step['observation']\n",
    "    print(f\"   {obs_preview}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "720eeea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOOL USAGE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total tool calls: 9\n",
      "Unique tools used: 2\n",
      "\n",
      "Tool usage breakdown:\n",
      "  â€¢ execute_bash: 7 times\n",
      "  â€¢ str_replace_editor: 2 times\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics of tool usage\n",
    "from collections import Counter\n",
    "\n",
    "tool_counts = Counter([step['tool_name'] for step in trajectory])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOOL USAGE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal tool calls: {len(trajectory)}\")\n",
    "print(f\"Unique tools used: {len(tool_counts)}\")\n",
    "print(\"\\nTool usage breakdown:\")\n",
    "for tool_name, count in tool_counts.most_common():\n",
    "    print(f\"  â€¢ {tool_name}: {count} times\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63244ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPACT TRAJECTORY VIEW\n",
      "================================================================================\n",
      "\n",
      "  1. execute_bash         (command='grep -R \"class SimpleLazyObject\" /workspace/django__django__3.1/django/utils/functional.py', security_risk='LOW') â†’ class SimpleLazyObject(LazyObject):\n",
      "[The command completed with exit code 0.]\n",
      "[C...\n",
      "  2. execute_bash         (command='grep -R \"def get_prep_value\" /workspace/django__django__3.1/django/db/models/fields/', security_risk='LOW') â†’ /workspace/django__django__3.1/django/db/models/fields/files.py:    def get_prep...\n",
      "  3. execute_bash         (command=\"sed -n '1,200p' /workspace/django__django__3.1/django/utils/functional.py\", security_risk='LOW') â†’ import copy\n",
      "import itertools\n",
      "import operator\n",
      "from functools import total_orderin...\n",
      "  4. execute_bash         (command=\"sed -n '1,300p' /workspace/django__django__3.1/django/db/models/fields/related.py\", security_risk='LOW') â†’ import functools\n",
      "import inspect\n",
      "from functools import partial\n",
      "\n",
      "from django impor...\n",
      "  5. execute_bash         (command=\"sed -n '960,980p' /workspace/django__django__3.1/django/db/models/fields/__init__.py\", security_risk='LOW') â†’ def get_prep_value(self, value):\n",
      "        value = super().get_prep_value(value)\n",
      " ...\n",
      "  6. execute_bash         (command='grep -R \"class IntegerField\" /workspace/django__django__3.1/django/db/models/fields', security_risk='LOW') â†’ /workspace/django__django__3.1/django/db/models/fields/__init__.py:class Integer...\n",
      "  7. str_replace_editor   (command='str_replace', path='/workspace/django__django__3.1/django/db/models/fields/__init__.py', old_str='class IntegerField(Field):', new_str='from django.utils.functional import SimpleLazyObject\\n\\nclass IntegerField(Field):') â†’ The file /workspace/django__django__3.1/django/db/models/fields/__init__.py has ...\n",
      "  8. execute_bash         (command=\"sed -n '1715,1800p' /workspace/django__django__3.1/django/db/models/fields/__init__.py\", security_risk='LOW') â†’ class IntegerField(Field):\n",
      "    empty_strings_allowed = False\n",
      "    default_error_m...\n",
      "  9. str_replace_editor   (command='str_replace', path='/workspace/django__django__3.1/django/db/models/fields/__init__.py', old_str='    def get_prep_value(self, value):\\n        value = super().get_prep_value(value)\\n        if val..., new_str='    def get_prep_value(self, value):\\n        value = super().get_prep_value(value)\\n        if val...) â†’ The file /workspace/django__django__3.1/django/db/models/fields/__init__.py has ...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Compact view showing just tool sequence\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPACT TRAJECTORY VIEW\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for step in trajectory:\n",
    "    args_summary = \", \".join([f\"{k}={repr(v)[:100]}...\" if len(repr(v)) > 100 else f\"{k}={repr(v)}\" \n",
    "                               for k, v in list(step['tool_args'].items())[:4]])  # Show first 2 args\n",
    "    obs_summary = step['observation'][:80] + \"...\" if len(step['observation']) > 80 else step['observation']\n",
    "    \n",
    "    print(f\"{step['step_num']:3d}. {step['tool_name']:20s} ({args_summary}) â†’ {obs_summary}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03173f79",
   "metadata": {},
   "source": [
    "# ðŸ” Code Flow: From LLM Response to Logged JSON\n",
    "\n",
    "## Where to Set Breakpoints for Debugging Empty Content\n",
    "\n",
    "Based on the codebase analysis, here's the complete flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef44469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "KEY FILES FOR DEBUGGING EMPTY CONTENT IN LLM RESPONSES\n",
      "================================================================================\n",
      "\n",
      "ðŸ“ Main LLM wrapper\n",
      "   /home/v-murongma/code/OpenHands_SWE-Bench-Optimized/openhands/llm/llm.py\n",
      "\n",
      "ðŸ“ Function call converter\n",
      "   /home/v-murongma/code/OpenHands_SWE-Bench-Optimized/openhands/llm/fn_call_converter.py\n",
      "\n",
      "================================================================================\n",
      "CRITICAL BREAKPOINT LOCATIONS\n",
      "================================================================================\n",
      "\n",
      "Breakpoint #1: wrapper() inside __init__\n",
      "  ðŸ“‚ File: openhands/llm/llm.py\n",
      "  ðŸ“ Line: ~338\n",
      "  â“ Why: RIGHT AFTER litellm returns the raw response\n",
      "  ðŸ’» Code:\n",
      "      resp: ModelResponse = self._completion_unwrapped(*args, **kwargs)\n",
      "  ðŸ” What to inspect: resp.choices[0].message.content - This is the RAW response from the LLM\n",
      "\n",
      "Breakpoint #2: wrapper() inside __init__\n",
      "  ðŸ“‚ File: openhands/llm/llm.py\n",
      "  ðŸ“ Line: ~383-418\n",
      "  â“ Why: Where the JSON is being constructed for logging\n",
      "  ðŸ’» Code:\n",
      "      _d = {\n",
      "          'messages': messages,\n",
      "          'response': resp,\n",
      "          'args': args,\n",
      "          'kwargs': {...},\n",
      "          'timestamp': time.time(),\n",
      "          'cost': cost,\n",
      "      }\n",
      "  ðŸ” What to inspect: _d[\"response\"] - This is what gets saved to the JSON file\n",
      "\n",
      "Breakpoint #3: wrapper() inside __init__\n",
      "  ðŸ“‚ File: openhands/llm/llm.py\n",
      "  ðŸ“ Line: ~378\n",
      "  â“ Why: Check the LLM response logging\n",
      "  ðŸ’» Code:\n",
      "      self.log_response(resp)\n",
      "  ðŸ” What to inspect: resp.choices[0].message - Check if content is already empty here\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Key file paths for debugging\n",
    "key_files = {\n",
    "    'Main LLM wrapper': '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/openhands/llm/llm.py',\n",
    "    'Function call converter': '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/openhands/llm/fn_call_converter.py',\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"KEY FILES FOR DEBUGGING EMPTY CONTENT IN LLM RESPONSES\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "for name, path in key_files.items():\n",
    "    print(f\"ðŸ“ {name}\")\n",
    "    print(f\"   {path}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CRITICAL BREAKPOINT LOCATIONS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "breakpoints = [\n",
    "    {\n",
    "        'file': 'openhands/llm/llm.py',\n",
    "        'line': '~338',\n",
    "        'function': 'wrapper() inside __init__',\n",
    "        'reason': 'RIGHT AFTER litellm returns the raw response',\n",
    "        'code': 'resp: ModelResponse = self._completion_unwrapped(*args, **kwargs)',\n",
    "        'what_to_inspect': 'resp.choices[0].message.content - This is the RAW response from the LLM'\n",
    "    },\n",
    "    {\n",
    "        'file': 'openhands/llm/llm.py',\n",
    "        'line': '~383-418',\n",
    "        'function': 'wrapper() inside __init__',\n",
    "        'reason': 'Where the JSON is being constructed for logging',\n",
    "        'code': '''_d = {\n",
    "    'messages': messages,\n",
    "    'response': resp,\n",
    "    'args': args,\n",
    "    'kwargs': {...},\n",
    "    'timestamp': time.time(),\n",
    "    'cost': cost,\n",
    "}''',\n",
    "        'what_to_inspect': '_d[\"response\"] - This is what gets saved to the JSON file'\n",
    "    },\n",
    "    {\n",
    "        'file': 'openhands/llm/llm.py',\n",
    "        'line': '~378',\n",
    "        'function': 'wrapper() inside __init__',\n",
    "        'reason': 'Check the LLM response logging',\n",
    "        'code': 'self.log_response(resp)',\n",
    "        'what_to_inspect': 'resp.choices[0].message - Check if content is already empty here'\n",
    "    },\n",
    "]\n",
    "\n",
    "for i, bp in enumerate(breakpoints, 1):\n",
    "    print(f\"Breakpoint #{i}: {bp['function']}\")\n",
    "    print(f\"  ðŸ“‚ File: {bp['file']}\")\n",
    "    print(f\"  ðŸ“ Line: {bp['line']}\")\n",
    "    print(f\"  â“ Why: {bp['reason']}\")\n",
    "    print(f\"  ðŸ’» Code:\")\n",
    "    for line in bp['code'].split('\\n'):\n",
    "        print(f\"      {line}\")\n",
    "    print(f\"  ðŸ” What to inspect: {bp['what_to_inspect']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea7fdd",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Complete Flow Diagram\n",
    "\n",
    "```\n",
    "1. Agent creates Message objects\n",
    "   â†“\n",
    "2. openhands/llm/llm.py::wrapper() (line ~230)\n",
    "   - Converts Message objects to dict format via format_messages_for_llm()\n",
    "   â†“\n",
    "3. openhands/llm/llm.py::wrapper() (line ~338)\n",
    "   - Calls litellm.completion() with messages\n",
    "   - âš¡ BREAKPOINT HERE: resp = self._completion_unwrapped(*args, **kwargs)\n",
    "   - This is the RAW response from OpenAI/Azure\n",
    "   â†“\n",
    "4. Response processing (line ~348-365)\n",
    "   - If mock_function_calling: convert response back to function calling format\n",
    "   - Otherwise: use response as-is\n",
    "   â†“\n",
    "5. Logging (line ~383-418)\n",
    "   - Creates dict with messages, response, kwargs, cost, timestamp\n",
    "   - âš¡ BREAKPOINT HERE: Check _d['response'].choices[0].message.content\n",
    "   - Writes to JSON file in log_completions_folder\n",
    "   â†“\n",
    "6. JSON file created (your data!)\n",
    "   - Location: evaluation_outputs/.../llm_completions/.../*.json\n",
    "```\n",
    "\n",
    "## ðŸŽ¯ Most Important Breakpoint\n",
    "\n",
    "**File**: `openhands/llm/llm.py`  \n",
    "**Line**: ~338 (inside the `wrapper` function)  \n",
    "**Code**: \n",
    "```python\n",
    "resp: ModelResponse = self._completion_unwrapped(*args, **kwargs)\n",
    "```\n",
    "\n",
    "**Why this is critical:**\n",
    "- This is IMMEDIATELY after litellm calls the LLM API\n",
    "- The `resp` object contains the raw, unmodified response from OpenAI/Azure\n",
    "- Check `resp.choices[0].message.content` here to see if the LLM itself returned empty content\n",
    "- If content is empty here, it means the LLM decided not to include text (normal behavior)\n",
    "- If content is NOT empty here but becomes empty later, there's a bug in processing\n",
    "\n",
    "## ðŸ”§ How to Debug\n",
    "\n",
    "### VSCode Debug Configuration\n",
    "\n",
    "Add this to `.vscode/launch.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"version\": \"0.2.0\",\n",
    "    \"configurations\": [\n",
    "        {\n",
    "            \"name\": \"Debug OpenHands Evaluation\",\n",
    "            \"type\": \"python\",\n",
    "            \"request\": \"launch\",\n",
    "            \"module\": \"openhands.core.main\",\n",
    "            \"args\": [\n",
    "                \"-t\", \"your_task_here\",\n",
    "                \"-c\", \"CodeActAgent\"\n",
    "            ],\n",
    "            \"console\": \"integratedTerminal\",\n",
    "            \"justMyCode\": false,\n",
    "            \"env\": {\n",
    "                \"LOG_COMPLETIONS\": \"true\",\n",
    "                \"LOG_COMPLETIONS_FOLDER\": \"./llm_logs\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Steps:\n",
    "1. Open `openhands/llm/llm.py`\n",
    "2. Set breakpoint at line ~338: `resp: ModelResponse = self._completion_unwrapped(*args, **kwargs)`\n",
    "3. Run the debug configuration\n",
    "4. When breakpoint hits, inspect:\n",
    "   - `resp.choices[0].message.content` - The actual LLM response content\n",
    "   - `resp.choices[0].message.tool_calls` - The tool calls (if any)\n",
    "   - `kwargs['messages']` - The input messages sent to LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba60db",
   "metadata": {},
   "source": [
    "## ðŸ§ª Alternative: Add Print Statements\n",
    "\n",
    "If you don't want to use a debugger, add these print statements:\n",
    "\n",
    "### In `openhands/llm/llm.py` around line 338:\n",
    "\n",
    "```python\n",
    "resp: ModelResponse = self._completion_unwrapped(*args, **kwargs)\n",
    "\n",
    "# ADD THIS DEBUG CODE:\n",
    "print(\"=\"*80)\n",
    "print(\"RAW LLM RESPONSE DEBUG\")\n",
    "print(\"=\"*80)\n",
    "if resp.choices and len(resp.choices) > 0:\n",
    "    msg = resp.choices[0].message\n",
    "    print(f\"Content type: {type(msg.content)}\")\n",
    "    print(f\"Content value: {repr(msg.content)}\")\n",
    "    print(f\"Content is empty: {not msg.content or (isinstance(msg.content, list) and not msg.content)}\")\n",
    "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        print(f\"Has tool_calls: YES ({len(msg.tool_calls)} calls)\")\n",
    "        for tc in msg.tool_calls:\n",
    "            print(f\"  - {tc.function.name}\")\n",
    "    else:\n",
    "        print(\"Has tool_calls: NO\")\n",
    "print(\"=\"*80)\n",
    "```\n",
    "\n",
    "This will show you EXACTLY what the LLM returns before any processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cff642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the exact line numbers by reading the file\n",
    "import os\n",
    "\n",
    "llm_file = '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/openhands/llm/llm.py'\n",
    "\n",
    "if os.path.exists(llm_file):\n",
    "    with open(llm_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"EXACT LINE NUMBERS FOR BREAKPOINTS\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Find the key lines\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        # Look for the completion call\n",
    "        if 'resp: ModelResponse = self._completion_unwrapped' in line:\n",
    "            print(f\"âœ… Line {i}: RAW LLM RESPONSE (PRIMARY BREAKPOINT)\")\n",
    "            print(f\"   {line.strip()}\")\n",
    "            print(f\"   Context:\")\n",
    "            for j in range(max(0, i-3), min(len(lines), i+3)):\n",
    "                marker = \" >>> \" if j+1 == i else \"     \"\n",
    "                print(f\"   {marker}{j+1:4d}: {lines[j].rstrip()}\")\n",
    "            print()\n",
    "        \n",
    "        # Look for the logging dict creation\n",
    "        if \"'messages': messages,\" in line and \"'response': resp,\" in lines[i]:\n",
    "            print(f\"âœ… Line {i}: LOGGING DICT CREATION\")\n",
    "            print(f\"   {line.strip()}\")\n",
    "            print(f\"   Context:\")\n",
    "            for j in range(max(0, i-2), min(len(lines), i+5)):\n",
    "                marker = \" >>> \" if j+1 == i else \"     \"\n",
    "                print(f\"   {marker}{j+1:4d}: {lines[j].rstrip()}\")\n",
    "            print()\n",
    "        \n",
    "        # Look for log_response call\n",
    "        if 'self.log_response(resp)' in line:\n",
    "            print(f\"âœ… Line {i}: LOG RESPONSE CALL\")\n",
    "            print(f\"   {line.strip()}\")\n",
    "            print()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"File not found: {llm_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd472449",
   "metadata": {},
   "source": [
    "# ðŸ” Where OpenHands Defines the Workflow/Instructions\n",
    "\n",
    "## Found: The workflow is defined in **Jinja2 template files**\n",
    "\n",
    "These templates are used to generate system prompts for different evaluation scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7c3fb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“ WORKFLOW/INSTRUCTION TEMPLATE FILES\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ swe_gpt4.j2\n",
      "   Path: /home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/benchmarks/swe_bench/prompts/swe_gpt4.j2\n",
      "   Use: Used for GPT-4 models (gpt-4.1, gpt-4o, etc.) in SWE-bench evaluation\n",
      "   Content: 8-step workflow with detailed instructions\n",
      "\n",
      "ðŸ“„ swe_default.j2\n",
      "   Path: /home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/benchmarks/swe_bench/prompts/swe_default.j2\n",
      "   Use: Default template for other models in SWE-bench evaluation\n",
      "   Content: 6-phase workflow (READING, RUNNING, EXPLORATION, TEST CREATION, FIX ANALYSIS, FIX IMPLEMENTATION)\n",
      "\n",
      "ðŸ“„ swt.j2\n",
      "   Path: /home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/benchmarks/swe_bench/prompts/swt.j2\n",
      "   Use: Template for test generation tasks\n",
      "   Content: Instructions for writing tests only (not fixing code)\n",
      "\n",
      "================================================================================\n",
      "ðŸ”§ HOW TEMPLATES ARE SELECTED\n",
      "================================================================================\n",
      "\n",
      "\n",
      "File: evaluation/benchmarks/swe_bench/run_infer.py (lines 110-133)\n",
      "\n",
      "Selection Logic:\n",
      "1. If metadata.instruction_template_name is set â†’ Use that template\n",
      "2. Elif mode starts with 'swt' â†’ Use 'swt.j2' \n",
      "3. Elif mode == 'swe':\n",
      "   - If 'gpt-4.1' in llm_model â†’ Use 'swe_gpt4.j2'\n",
      "   - Else â†’ Use 'swe_default.j2'\n",
      "4. Else â†’ Fallback to 'swe_default.j2'\n",
      "\n",
      "The template is then rendered using Jinja2 with the instance data:\n",
      "- instance.problem_statement\n",
      "- instance.base_commit\n",
      "- workspace_dir_name\n",
      "etc.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Display the workflow/instruction template files\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸ“ WORKFLOW/INSTRUCTION TEMPLATE FILES\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "template_files = {\n",
    "    'swe_gpt4.j2': {\n",
    "        'path': '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/benchmarks/swe_bench/prompts/swe_gpt4.j2',\n",
    "        'description': 'Used for GPT-4 models (gpt-4.1, gpt-4o, etc.) in SWE-bench evaluation',\n",
    "        'contains': '8-step workflow with detailed instructions'\n",
    "    },\n",
    "    'swe_default.j2': {\n",
    "        'path': '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/benchmarks/swe_bench/prompts/swe_default.j2',\n",
    "        'description': 'Default template for other models in SWE-bench evaluation',\n",
    "        'contains': '6-phase workflow (READING, RUNNING, EXPLORATION, TEST CREATION, FIX ANALYSIS, FIX IMPLEMENTATION)'\n",
    "    },\n",
    "    'swt.j2': {\n",
    "        'path': '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/benchmarks/swe_bench/prompts/swt.j2',\n",
    "        'description': 'Template for test generation tasks',\n",
    "        'contains': 'Instructions for writing tests only (not fixing code)'\n",
    "    }\n",
    "}\n",
    "\n",
    "for filename, info in template_files.items():\n",
    "    print(f\"ðŸ“„ {filename}\")\n",
    "    print(f\"   Path: {info['path']}\")\n",
    "    print(f\"   Use: {info['description']}\")\n",
    "    print(f\"   Content: {info['contains']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸ”§ HOW TEMPLATES ARE SELECTED\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "selection_logic = \"\"\"\n",
    "File: evaluation/benchmarks/swe_bench/run_infer.py (lines 110-133)\n",
    "\n",
    "Selection Logic:\n",
    "1. If metadata.instruction_template_name is set â†’ Use that template\n",
    "2. Elif mode starts with 'swt' â†’ Use 'swt.j2' \n",
    "3. Elif mode == 'swe':\n",
    "   - If 'gpt-4.1' in llm_model â†’ Use 'swe_gpt4.j2'\n",
    "   - Else â†’ Use 'swe_default.j2'\n",
    "4. Else â†’ Fallback to 'swe_default.j2'\n",
    "\n",
    "The template is then rendered using Jinja2 with the instance data:\n",
    "- instance.problem_statement\n",
    "- instance.base_commit\n",
    "- workspace_dir_name\n",
    "etc.\n",
    "\"\"\"\n",
    "\n",
    "print(selection_logic)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdbd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read and display the GPT-4 workflow template\n",
    "swe_gpt4_path = '/home/v-murongma/code/OpenHands_SWE-Bench-Optimized/evaluation/benchmarks/swe_bench/prompts/swe_gpt4.j2'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸ“‹ FULL CONTENT: swe_gpt4.j2 (The workflow you're asking about)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "with open(swe_gpt4_path, 'r') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "print(content)\n",
    "print()\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e4e191",
   "metadata": {},
   "source": [
    "## ðŸ“Š Summary: Where the Workflow is Defined\n",
    "\n",
    "### Main Discovery\n",
    "\n",
    "The **8-step workflow** you referenced is defined in:\n",
    "\n",
    "**File**: `/evaluation/benchmarks/swe_bench/prompts/swe_gpt4.j2`\n",
    "\n",
    "**Purpose**: This is a **Jinja2 template** that generates the system instruction prompt for GPT-4 models when evaluating on SWE-bench tasks.\n",
    "\n",
    "### Key Points\n",
    "\n",
    "1. **It's a Prompt Template, Not Code**\n",
    "   - This workflow is not embedded in Python code\n",
    "   - It's a text template that gets rendered and sent as instructions to the LLM\n",
    "   - The LLM (GPT-4) receives this as its system/instruction prompt\n",
    "\n",
    "2. **When It's Used**\n",
    "   - Selected automatically when:\n",
    "     - Running SWE-bench evaluation\n",
    "     - Using a GPT-4 model (detected by 'gpt-4.1' in model name)\n",
    "     - Mode is 'swe' (not 'swt')\n",
    "   \n",
    "3. **Template Rendering Process**\n",
    "   ```\n",
    "   run_infer.py â†’ Detects GPT-4 model\n",
    "                â†’ Loads swe_gpt4.j2 template\n",
    "                â†’ Renders with Jinja2 (fills in instance.problem_statement, base_commit, etc.)\n",
    "                â†’ Sends rendered text as instruction to LLM\n",
    "   ```\n",
    "\n",
    "4. **The 8 Steps in the Workflow**\n",
    "   1. Understand the problem deeply\n",
    "   2. Investigate the codebase\n",
    "   3. Develop a clear, step-by-step plan\n",
    "   4. Implement the fix incrementally\n",
    "   5. Debug as needed\n",
    "   6. Test frequently\n",
    "   7. Iterate until fixed\n",
    "   8. Reflect and validate comprehensively\n",
    "\n",
    "### Related Files\n",
    "\n",
    "- **Template Selector**: `evaluation/benchmarks/swe_bench/run_infer.py` (lines 110-133)\n",
    "- **Other Templates**:\n",
    "  - `swe_default.j2`: For non-GPT-4 models (6-phase workflow)\n",
    "  - `swt.j2`: For test-writing tasks\n",
    "\n",
    "### How to Modify\n",
    "\n",
    "If you want to change the workflow:\n",
    "1. Edit the template file directly: `evaluation/benchmarks/swe_bench/prompts/swe_gpt4.j2`\n",
    "2. The changes will be applied to all future evaluations using GPT-4 models\n",
    "3. No code recompilation needed - it's just a text template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a67136",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ How to Specify Which Prompt Template to Use\n",
    "\n",
    "## Method 1: Environment Variable (Recommended)\n",
    "\n",
    "Set the `INSTRUCTION_TEMPLATE_NAME` environment variable before running evaluation:\n",
    "\n",
    "```bash\n",
    "export INSTRUCTION_TEMPLATE_NAME=swe_custom.j2\n",
    "```\n",
    "\n",
    "Then run your evaluation script:\n",
    "```bash\n",
    "./evaluation/benchmarks/swe_bench/scripts/run_infer.sh llm.eval_gpt4_1106_preview HEAD CodeActAgent 10\n",
    "```\n",
    "\n",
    "## Method 2: Set in Your Shell Script\n",
    "\n",
    "Add it to your evaluation script:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "export INSTRUCTION_TEMPLATE_NAME=swe_custom.j2\n",
    "python evaluation/benchmarks/swe_bench/run_infer.py ...\n",
    "```\n",
    "\n",
    "## Where It's Configured\n",
    "\n",
    "### 1. Environment Variable Reading\n",
    "**File**: `evaluation/utils/shared.py` (line 209)\n",
    "\n",
    "```python\n",
    "metadata = EvalMetadata(\n",
    "    agent_class=agent_class,\n",
    "    llm_config=llm_config,\n",
    "    # ... other fields ...\n",
    "    instruction_template_name=os.environ.get('INSTRUCTION_TEMPLATE_NAME'),\n",
    ")\n",
    "```\n",
    "\n",
    "### 2. Template Selection Logic\n",
    "**File**: `evaluation/benchmarks/swe_bench/run_infer.py` (lines 115-133)\n",
    "\n",
    "```python\n",
    "def get_instruction(instance: pd.Series, metadata: EvalMetadata) -> MessageAction:\n",
    "    # ...\n",
    "    \n",
    "    # Determine the template file based on mode and LLM\n",
    "    if metadata.instruction_template_name:\n",
    "        # âœ… YOUR CUSTOM TEMPLATE GETS PRIORITY!\n",
    "        template_name = metadata.instruction_template_name\n",
    "    elif mode.startswith('swt'):\n",
    "        template_name = 'swt.j2'\n",
    "    elif mode == 'swe':\n",
    "        if 'gpt-4.1' in llm_model:\n",
    "            template_name = 'swe_gpt4.j2'\n",
    "        else:\n",
    "            template_name = 'swe_default.j2'\n",
    "    else:\n",
    "        template_name = 'swe_default.j2'\n",
    "    \n",
    "    # Template is loaded from: evaluation/benchmarks/swe_bench/prompts/\n",
    "    prompts_dir = os.path.join(os.path.dirname(__file__), 'prompts')\n",
    "    env = Environment(loader=FileSystemLoader(prompts_dir))\n",
    "    template = env.get_template(template_name)\n",
    "```\n",
    "\n",
    "## Available Templates\n",
    "\n",
    "Templates are located in: `evaluation/benchmarks/swe_bench/prompts/`\n",
    "\n",
    "1. **swe_gpt4.j2** - 8-step workflow for GPT-4 models\n",
    "2. **swe_default.j2** - 6-phase workflow for other models\n",
    "3. **swt.j2** - Test-writing template\n",
    "\n",
    "## Creating Your Own Template\n",
    "\n",
    "### Step 1: Create Template File\n",
    "Create a new file in `evaluation/benchmarks/swe_bench/prompts/`:\n",
    "\n",
    "```bash\n",
    "cd evaluation/benchmarks/swe_bench/prompts/\n",
    "cp swe_gpt4.j2 my_custom_prompt.j2\n",
    "# Edit my_custom_prompt.j2 with your workflow\n",
    "```\n",
    "\n",
    "### Step 2: Use Your Template\n",
    "```bash\n",
    "export INSTRUCTION_TEMPLATE_NAME=my_custom_prompt.j2\n",
    "```\n",
    "\n",
    "### Step 3: Run Evaluation\n",
    "```bash\n",
    "./evaluation/benchmarks/swe_bench/scripts/run_infer.sh llm.eval_gpt4_1106_preview HEAD CodeActAgent 10\n",
    "```\n",
    "\n",
    "## Template Variables Available\n",
    "\n",
    "Your Jinja2 template can use these variables:\n",
    "\n",
    "```jinja\n",
    "{{ instance.problem_statement }}   # The issue description\n",
    "{{ instance.base_commit }}          # Git commit to compare against\n",
    "{{ workspace_dir_name }}            # Workspace directory name\n",
    "{{ metadata }}                      # Full metadata object\n",
    "{{ test_instructions }}             # (swt-ci mode only) Test command\n",
    "```\n",
    "\n",
    "## Example: Testing Your Template\n",
    "\n",
    "```bash\n",
    "# Set your custom template\n",
    "export INSTRUCTION_TEMPLATE_NAME=my_custom_prompt.j2\n",
    "\n",
    "# Run on a single instance for testing\n",
    "python evaluation/benchmarks/swe_bench/run_infer.py \\\n",
    "    --agent-cls CodeActAgent \\\n",
    "    --llm-config llm.eval_gpt4_1106_preview \\\n",
    "    --max-iterations 30 \\\n",
    "    --eval-num-workers 1 \\\n",
    "    --eval-n-limit 1\n",
    "```\n",
    "\n",
    "## Priority Order (Highest to Lowest)\n",
    "\n",
    "1. âœ… **INSTRUCTION_TEMPLATE_NAME env variable** (Your choice!)\n",
    "2. Mode 'swt*' â†’ `swt.j2`\n",
    "3. Mode 'swe' + 'gpt-4.1' in model â†’ `swe_gpt4.j2`\n",
    "4. Mode 'swe' + other models â†’ `swe_default.j2`\n",
    "5. Fallback â†’ `swe_default.j2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe133e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference code snippet\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸš€ QUICK START: Using Custom Prompt Template\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "code_example = '''\n",
    "# In your terminal or script:\n",
    "\n",
    "# 1. Set the environment variable\n",
    "export INSTRUCTION_TEMPLATE_NAME=my_custom_prompt.j2\n",
    "\n",
    "# 2. Run your evaluation\n",
    "./evaluation/benchmarks/swe_bench/scripts/run_infer.sh \\\\\n",
    "    llm.eval_gpt4_1106_preview \\\\\n",
    "    HEAD \\\\\n",
    "    CodeActAgent \\\\\n",
    "    10\n",
    "\n",
    "# OR, set it inline:\n",
    "INSTRUCTION_TEMPLATE_NAME=my_custom_prompt.j2 \\\\\n",
    "python evaluation/benchmarks/swe_bench/run_infer.py \\\\\n",
    "    --agent-cls CodeActAgent \\\\\n",
    "    --llm-config llm.eval_gpt4_1106_preview \\\\\n",
    "    --max-iterations 30\n",
    "\n",
    "# That's it! Your custom template will be used instead of the default.\n",
    "'''\n",
    "\n",
    "print(code_example)\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸ“ KEY FILES TO KNOW\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"Template Location:\")\n",
    "print(\"  â””â”€ evaluation/benchmarks/swe_bench/prompts/\")\n",
    "print(\"     â”œâ”€ swe_gpt4.j2       (Default for GPT-4 models)\")\n",
    "print(\"     â”œâ”€ swe_default.j2    (Default for other models)\")\n",
    "print(\"     â”œâ”€ swt.j2            (For test writing)\")\n",
    "print(\"     â””â”€ YOUR_CUSTOM.j2    (Your custom prompt)\")\n",
    "print()\n",
    "print(\"Configuration Files:\")\n",
    "print(\"  â”œâ”€ evaluation/utils/shared.py:209\")\n",
    "print(\"  â”‚  â””â”€ Reads INSTRUCTION_TEMPLATE_NAME env variable\")\n",
    "print(\"  â””â”€ evaluation/benchmarks/swe_bench/run_infer.py:115-133\")\n",
    "print(\"     â””â”€ Template selection logic\")\n",
    "print()\n",
    "print(\"Documentation:\")\n",
    "print(\"  â””â”€ evaluation/benchmarks/swe_bench/README.md:98\")\n",
    "print(\"     â””â”€ Usage instructions\")\n",
    "print()\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openhands-swebench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
